{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "solution": "hidden"
   },
   "source": [
    "## Array Operations with Numpy\n",
    "\n",
    "**Nick Kern**\n",
    "<br>\n",
    "**Astro 9: Python Programming in Astronomy**\n",
    "<br>\n",
    "**UC Berkeley**\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"imgs/numpy.jpg\" width=300px/>\n",
    "\n",
    "Now that we've covered the basic functionalities of \"pure Python\" we will move on to explore the Python packages that really make Python a powerful tool for scientific analyses. One such packages are the Numerical Python (NumPy) package: if this package didn't exist, it is unlikely that Python would be used within the scientific community to the extent it is today.\n",
    "\n",
    "In brief, Numpy is a package that provides an \"array\" data structure, and further provides modules that enable us to perform all kinds of mathematical operations (e.g., linear algebra) on those arrays. You can kind of think of a numpy array (called an `ndarray`) as a \"multidimensional container of items of the same data type and size.\" Arrays can be sliced and indexed like lists, but can also be rotated, matrix multiplied, \"fancy indexed,\" transposed, etc. There are lots of things we can do with arrays. What's more, array operations with numpy are generally considerably faster than using a `for` loop and lists. This is due to a few reasons, one of which is because numpy runs on compiled C code, and another is its efficient storage and sharing of data within the array object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# load numpy like this\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "### The `numpy ndarray`\n",
    "\n",
    "Numpy allows us to work with N-dimensional arrays, or `ndarrays`. One prominent difference between Numpy arrays and Python lists is the fact that all elements within a Numpy array **need to have the same data type**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# define our first array\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(arr)\n",
    "\n",
    "print(arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you assign an element to have a different data type, all other elements must conform. You can do this implicitly, or explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# numpy implicitly knows to convert the integers to a float\n",
    "arr = np.array([1.23, 4, 5, 6])\n",
    "\n",
    "print(arr)\n",
    "\n",
    "print(arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explicity setting the data type\n",
    "arr = np.array([1.23, 4, 5, 6], dtype=np.complex)\n",
    "\n",
    "print(arr)\n",
    "\n",
    "print(arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays, like lists, **are mutable**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arrays, like lists, are mutable\n",
    "arr = np.array([0, 0.5, 1, 1.5, 2])\n",
    "\n",
    "print(arr, hex(id(arr)))\n",
    "\n",
    "arr[0] = -0.5\n",
    "\n",
    "print(arr, hex(id(arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# putting the N in ndarray\n",
    "arr = np.array([ [1,2,3], [4,5,6], [7,8,9]])\n",
    "\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arrays are objects, and thus have attributes and methods!\n",
    "print(arr.ndim)\n",
    "\n",
    "print(arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy arrays are objects, and as such have attributes and methods. Along with `.ndim` and `.shape`, other useful methods are `.astype` to convert to different data types, `.max` and `.min` for maximum and minimum values, and `.ravel` for \"unraveling\" a multi-dimensional array into a 1D array and `.resize` and `.reshape` for reshaping an array.\n",
    "\n",
    "### Easily Creating Arrays\n",
    "\n",
    "If we want to create an array, we don't need to fill it with elements by hand. Like the `range()` function for lists, the numpy array has a *range* of functions for building arrays easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.arange similar to range capability, but returns an array, not an iterator\n",
    "np.arange(0, 22, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.linspace for specifying number of elements, rather than step-size with arange (it has inclusive upper bound!)\n",
    "np.linspace(0, 20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of ones\n",
    "np.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of zeros\n",
    "np.zeros(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of 2D ones\n",
    "np.ones( (2, 5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2d array from 0 - 15\n",
    "np.arange(0, 16).reshape(2, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list of random numbers from [0, 1)\n",
    "np.random.random( 5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Slicing and Fancy Indexing\n",
    "\n",
    "[draw a picture]\n",
    "\n",
    "Like lists, we can slice into a numpy array, however, with the numpy `ndarray` we can perform multi-dimensional slicing. Remember when slicing, the *start is inclusive*, while the *end is exclusive*. Note that the **zeroth axis** of a 2D array is along the vertical, and the **first axis** is along the horizontal.\n",
    "\n",
    "A quick way to generate an array is the `np.arange` function, similar to the built-in `range` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a 4x4 array\n",
    "arr = np.arange(16)\n",
    "\n",
    "arr.resize(4,4)\n",
    "\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slice along 0th axis\n",
    "print(arr[2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# alice along 1st axis\n",
    "print(arr[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# take a subsection\n",
    "print(arr[1:3, 1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution": "hidden",
    "solution_first": true
   },
   "source": [
    "### Breakout \n",
    "\n",
    "How might we slice an array to get these results?\n",
    "\n",
    "<img src=\"imgs/2D_slicing.jpg\" width=300px/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# breakout\n",
    "arr = np.arange(11, 36).reshape(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[ 1:4:1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[0, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[::2, ::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fancy indexing** is like slicing, but allows us to control exactly which elements we want to pull out of the array: we aren't limited to a row (red), column (blue), or elements that are evenly space apart from each other (green). Fancy indexing essentially creates a new `ndarray` composed of any combination of the elements in the initial array. Let's say we wanted the first, second and fourth columns of our previous 2d array. We index this the same way as before, but now we **feed a list** instead of an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take rows\n",
    "print(arr[ [0, 1, 3], : ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[range(5), range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Repeatedly take rows\n",
    "print(arr[ [0, 1, 3, 3, 3, 2, 1, 0], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick out just 16, 24 and 32\n",
    "print( arr[ [1, 2, 4], [0, 3, 1] ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Recall that when we performed straight assignment of **lists** we were **copying references**, and when we sliced lists we were creating **new copies** of the object. This allowed us to get around the pitfalls of mutable objects and accidental element assignment. However, for an `ndarray`, a slice creates a **view** of the original array, which is an object that has a different memory address but still **shares data** with the original array. This means that, similar to our mutable list example, we can get unexpected behavior if we are loose with how we assign our arrays and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# data manipulation example\n",
    "arr1 = np.arange(16).reshape(4,4)\n",
    "\n",
    "arr2 = arr1[1:3, 1:3]\n",
    "\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign to arr2\n",
    "arr2[:, :] = np.arange(100,104).reshape(2, 2)\n",
    "\n",
    "print(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a copy by performing arithmetic, or by using .copy()\n",
    "arr1 = np.arange(16).reshape(4,4)\n",
    "\n",
    "arr2 = arr1[1:3, 1:3] * 1\n",
    "\n",
    "arr2[:, :] = np.arange(100, 104).reshape(2,2)\n",
    "\n",
    "print(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Indexing with Boolean Arrays and the `np.where` function\n",
    "\n",
    "Comparison operators on an `ndarray` will yield another `ndarray` with a boolean data type. The boolean array is the same shape as the original array, and is `True` where the condition is met and `False` where it isn't. We can then fancy index with these arrays to eliminate elements that don't conform. This is a fast and easy way to pick through an array for desired elements. Take the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an array\n",
    "arr = np.arange(25).reshape(5, 5)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create mask\n",
    "mask = arr > 10\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select out elements with fancy indexing\n",
    "arr[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`np.where`** statement can be used in two different ways. The first way accomplishes the same thing as the boolean mask, in that you feed the where statement a condition, it returns a set of lists which you can then feed into array to fancy index only the elements you wanted. The difference here is that instead of returning a boolean array of the same dimension as your original, it returns a series of lists with indices, which performs fancy indexing similar to how we originally did it. It looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fancy indexing with np.where\n",
    "fancy = np.where(arr > 10)\n",
    "\n",
    "fancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[fancy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can put more than one conditional in the `np.where` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fancy = np.where( (arr > 10) & (arr < 15) )\n",
    "print(arr[fancy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's nice about this way of fancy indexing, is that you also get the indices of the desired elements from the original array, which may be useful or necessary depending on what you are doing.\n",
    "\n",
    "The other way of using `np.where` is to perform a true masking of the original array, while keeping its structure intact and assigning the `False` elements some pre-defined value. It looks something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# true masking\n",
    "np.where(arr > 10, arr, -10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here the syntax is\n",
    "```\n",
    "np.where(<condition>, value if True, value if False)\n",
    "```\n",
    "\n",
    "You can see that the original array is neatly kept intact and we can clearly see which elements are undesired. We introduced a new type in doing so, the numpy NaN, or Not a Number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Numpy NaN\n",
    "\n",
    "NaNs can be both helpful and extremely annoying to deal with at the same time. What's nice about them is that they are definitely not a number, meaning that if you are uncomfortable about masking with a 0, `np.inf`, or some other number, you can mask with a `np.nan` and your array will retain its data type. You couldn't, for example, mask with a `None` type and retain an arbitrary data type (try it!). However, as we will see when we get to array arithmetic, performing arithmetic over arrays that have even a single `np.nan` can mess up your whole code. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum the elements of this array!\n",
    "arr = np.arange(10.0)\n",
    "print(np.sum(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sum when one element is a nan\n",
    "arr[0] = np.nan\n",
    "\n",
    "print(arr)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(np.sum(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "What's doubly annoying, is that, for whatever reason, they don't obey comparison operators. Meaning that if you have a large array with one or two `np.nan`s in them, you can't search for them with a `np.where(arr == np.nan)` statement. Howevever, the good people at NumPy anticipated this and provide us with the `np.isnan` function, which is like a special `np.where` function that works specially for `np.nan` types. Instead of returning indices, as the `np.where` statement returns, it returns a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.isnan(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a np.nan mask\n",
    "mask = np.isnan(arr)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perform sum w/ np.nan masked!\n",
    "np.sum( arr[~mask] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice we reversed the booleans in order to turn it into a proper mask before summing.\n",
    "\n",
    "It turns out there are also `np.nan`-safe functions within Numpy that can also do this without us having to think too hard, like `np.nansum`.\n",
    "\n",
    "In addition, there is an entire sub-module within numpy, called `ma` for Masked Arrays, that automates this and makes handling masked numpy `ndarrays` much easier. Check it out sometime! We may come back to it later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Concatenating\n",
    "\n",
    "Let's now look at ways in which we can combine (or concatenate) arrays. Recall that with lists and tuples, we did this with a simple addition operator `+`. With numpy arrays, as we will see, we will want to reserve that operator for actual arithmetic.\n",
    "\n",
    "There are multiple ways to **concatenate arrays**, depending on how you'd like to combine them.\n",
    "\n",
    "1.) The most straightforward way is to just create a new `np.array` object wrapped around the constituent arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this will stack along the zeroth axis\n",
    "arr1 = np.arange(10)\n",
    "arr2 = np.arange(10, 20)\n",
    "arr3 = np.arange(20,30)\n",
    "\n",
    "big_arr = np.array([arr1, arr2, arr3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what is the shape of big_arr?\n",
    "big_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2.) We can also use the `np.vstack` method, which stacks along the zeroth axis, similar to before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vstack([arr1, arr2, arr3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Use `np.hstack`, which stacks along the first axis (similar to `list.extend`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.hstack([arr1, arr2, arr3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) Use `np.dstack`, which stacks along the second axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "solution": "hidden"
   },
   "outputs": [],
   "source": [
    "np.dstack([arr1, arr2, arr3]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.append` works similarly to the above functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `numpy.loadtxt` for easy text file I/O\n",
    "\n",
    "Use the `numpy.loadtxt()` function to easily load in text files. You can feed it a filename and a delimiter string to tell it how to break up the data in the text file. By default, that delimiter is any whitespace. For a `.csv` or (comma-separated-values) file, we will want to choose a delimiter of `','` or a comma. Let's load in the `.csv` file we worked with before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# first lets inspect the file\n",
    "less ../02_IntroPython/random.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in all information and assign it to variable data\n",
    "data = np.loadtxt('../02_IntroPython/random.csv', delimiter=',')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakout\n",
    "\n",
    "1.\n",
    "Load in the file `clusters.csv` with the `np.loadtxt` function, keeping only the columns labeled as `haloid`, `r200crit`, and `m200crit`. You will want to inspect the header of the file to see which columns these labels correspond to. Find the HaloID corresponding to the cluster with an `r200crit` > 1.0 **and** an `m200crit` < $2\\times10^{4}$. Note that HaloID should have data as integers, meaning you will want to break off that component of the data into a separate array with `int` data type, and keep the other two (which are floats) in a single `ndarray` with `float` data type.\n",
    "\n",
    "2.\n",
    "Now load in the the column `vdispmean` and concatenate this into your data `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt('clusters.csv', delimiter=',')\n",
    "data = data[:, [0, 5, 6]]\n",
    "haloid = data[:, 0].astype(np.int)\n",
    "data = data[:, 1:]\n",
    "select = np.where( (data[:,0]>1) & (data[:,1]<2e4) )\n",
    "print(\"HaloID = {}\".format(haloid[select]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "less clusters.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vdispmean = np.loadtxt('clusters.csv',delimiter=',')[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.hstack( [ data, vdispmean.reshape(-1, 1) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array Arithmetic and Broadcasting\n",
    "\n",
    "One of the great things about arrays is our ability to perform math on them, element-by-element. This occurs exactly as you might suspect: a scalar times an array is just another array with its elements multiplied by that scalar. Let's briefly review. Note that in the case of array-array arithmetic, the **arrays need to have the same size**! Otherwise, Numpy doesn't know how to match up the excess indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array arithmetic\n",
    "arr1 = np.arange(10)\n",
    "arr2 = np.arange(10,20)\n",
    "print(arr1)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arr * arr multiplication\n",
    "arr1 * arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arr + arr addition\n",
    "arr1 + arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are sometimes exceptions to the rule I stated above, that for array arithmetic to work the arrays need to have the same shape. The exceptions are when Numpy can identify what it thinks you are trying to do, performs the array operations efficiently without making extra copies of data, and extends the resultant array to match what it thinks you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# arr / scalar division\n",
    "arr2 / 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One example of this is what we just did: scalar -- array arithmetic! In this case, numpy knows that we we mean by `arr2 / 2.0` is actually `arr2 / array([2.0, 2.0, ..., 2.0])`. Here, numpy \"broadcasts\" the 2.0 into an array and performs the operations element-by-element as we would expect. Broadcasting can also work between arrays of different shapes, exemplified by the figure below.\n",
    "\n",
    "<img src=\"imgs/broadcast.png\" width=600px/>\n",
    "<center>IC: astroML </center>\n",
    "\n",
    "Do we expect the following broadcasting operations to work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr1 = np.ones( (2, 3) )\n",
    "arr2 = np.ones( (2, 1) )\n",
    "\n",
    "arr1 + arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr1 = np.ones( (2, 3) )\n",
    "arr2 = np.ones( (2) )\n",
    "\n",
    "arr1 + arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr1 = np.ones( (2, 3) )\n",
    "arr2 = np.ones( (3) )\n",
    "\n",
    "arr1 + arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did one of the broadcasting rules above not work, while the other did? That is because when we try to broadcast into another array with a different dimension, the original array is first converted to the same dimensionality by putting ones in front, i.e., $(3) => (1, 3)$. We can see that this leads to only one of the last two examples above which has at least one matching dimension to anchor the broadcast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Array Arithmetic Example: Gravitational Force Calculation**\n",
    "\n",
    "We can also use mathematical functions directly on arrays, which will be applied onto the array element-by-element. Take the following example. The gravitational force between two masses, $M$ and $m$, separated by a distance $r$, can be expressed as\n",
    "\\begin{align}\n",
    "F = \\frac{GMm}{r^{2}}\n",
    "\\end{align}\n",
    "where $G$ is the gravitational constant of $6.67\\times10^{-11}$ m$^{3}$ kg$^{-1}$ s$^{-2}$. Say we have $M=10$kg and $m=5$kg, and we want to evaluate the force when the distance $r$ ranges from $1 < r < 10$ m in steps of $1$ m.\n",
    "\n",
    "\n",
    "We can write this into a function for $F$ given $r$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = 6.67e-11\n",
    "M = 10\n",
    "m = 5\n",
    "def Fgrav(r):\n",
    "    return G * M * m / r**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to solve for $F$ when $1 < r < 10$ is with a **`for` loop and a list**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_range = range(1, 10000, 1)\n",
    "force = []\n",
    "for r in r_range:\n",
    "    force.append( Fgrav(r) )\n",
    "\n",
    "force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way, which is both faster, more elegant and easier to read is to **feed a whole `np.ndarray` into the function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_range = np.arange(1, 10000, 1)\n",
    "force = Fgrav(r_range)\n",
    "\n",
    "force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Operations\n",
    "\n",
    "`numpy` is also particularly useful for performing matrix operations and linear algebra. Let's look at the dot product function `np.dot()`. If the shapes of the incoming arrays don't match, try using `.T` for transpose. There are lots of other matrix operations, like `np.cross`, `np.inner`, `np.outer` and `np.trace`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec1 = np.arange(4)\n",
    "mat1 = np.arange(8).reshape(2, 4)\n",
    "mat2 = np.arange(16).reshape(4,4)\n",
    "\n",
    "print(vec1)\n",
    "print(\"\")\n",
    "print(mat1)\n",
    "print(\"\")\n",
    "print(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dot product of two vectors\n",
    "np.dot(vec1, vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dot product of mat1 and mat1\n",
    "np.dot(mat1, mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dot product of mat1 and mat2\n",
    "np.dot(mat1, mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm for ourselves that the cartesian unit vectors in ($x, y, z$) are orthogonal (i.e. their projection onto each other yields zero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_x =\n",
    "unit_y =\n",
    "unit_z =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed Considerations\n",
    "\n",
    "It is useful to consider the speed of the calculations we are performing, particularly when working with extremely large arrays (think million of elements or larger). Here we will run through some examples which highlight some efficiencies to keep in mind while using `numpy`.\n",
    "\n",
    "1.) Making large place-holder arrays? Use `np.empty`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generating a blank million-element array\n",
    "\n",
    "%timeit np.empty(1000000)\n",
    "\n",
    "%timeit np.zeros(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2.) `Numpy` views are fast for data inspection and manipulation. Take-away here is to use `numpy ndarrays` over built-in data structures when possible and when it makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# view / copy difference\n",
    "N = 1000000\n",
    "l1 = list(range(N))\n",
    "a1 = np.arange(N)\n",
    "\n",
    "%timeit l2 = l1[:]\n",
    "%timeit a2 = a1[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "3.) While traditional slicing of and `ndarray` creates a view, fancy indexing creates a copy, meaning it is significantly slower when operating over large arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# slicing / fancy indexing difference\n",
    "arr = np.arange(1000000)\n",
    "\n",
    "# slicing\n",
    "%timeit arr[1000:100000]\n",
    "\n",
    "# fancy indexing w/ a list\n",
    "%timeit arr[range(1000, 100000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "4.) Array operations are faster at element-by-element arithmetic than a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array arithmetic is much faster than a simple FOR loop\n",
    "def recipricol(values):\n",
    "    # initialize empty array\n",
    "    recips = np.empty( len(values) )\n",
    "    # use enumerate for a FOR loop\n",
    "    for i, val in enumerate(values):\n",
    "        recips[i] = 1.0 / val\n",
    "    # return output\n",
    "    return recips\n",
    "\n",
    "arr = np.arange(1., 10000.)\n",
    "%timeit recipricol( arr )\n",
    "%timeit 1 / arr"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
